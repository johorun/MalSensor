from sqlite3 import Time
import networkx as nx
import time
import argparse
import csv
import numpy as np
import os
from multiprocessing import Pool as ThreadPool
from functools import partial
import glob
import random
from sklearn.model_selection import KFold
from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score
from itertools import islice

def parseargs():
    parser = argparse.ArgumentParser(description='Malware Detection with centrality.')
    parser.add_argument('-d', '--dir', help='The path of a dir contains feature_CSV.', required=True)
    parser.add_argument('-o', '--output', help='The path of output.', required=True)
    parser.add_argument('-t', '--type', help='The type of centrality: degree, closeness, harmonic, katz', required=True)

    args = parser.parse_args()
    return args

def feature_extraction(file):
    vectors = []
    labels = []
    with open(file, 'r') as f:
        csv_data = csv.reader(f)    #把每行的元素作为列表元素返回
        for line in islice(csv_data, 1, None):      #从第二行开始读取数据
            vector = [float(i) for i in line[1:-1]] #每个程序的向量从第二位（第一位是sha256）开始到倒数第二位,每个元素作为列表的元素转换float
            label = int(float(line[-1]))            #最后一位是标签
            vectors.append(vector)                  #vectors=[[0,0,1,0,1,0...], [vector2], ... ]
            labels.append(label)

    return vectors, labels

def degree_centrality_feature(feature_dir):
    feature_csv = feature_dir + 'pre_degree_multi_features.csv'
    vectors, labels = feature_extraction(feature_csv)
    feature_csv = feature_dir + 'post_degree_multi_features.csv'
    vectors1, labels1 = feature_extraction(feature_csv)
    return vectors, labels, vectors1, labels1

def katz_centrality_feature(feature_dir):
    feature_csv = feature_dir + 'pre_katz_multi_features.csv'
    vectors, labels = feature_extraction(feature_csv)
    feature_csv = feature_dir + 'post_katz_multi_features.csv'
    vectors1, labels1 = feature_extraction(feature_csv)
    return vectors, labels, vectors1, labels1

def closeness_centrality_feature(feature_dir):
    feature_csv = feature_dir + 'pre_closeness_multi_features.csv'
    vectors, labels = feature_extraction(feature_csv)
    feature_csv = feature_dir + 'post_closeness_multi_features.csv'
    vectors1, labels1 = feature_extraction(feature_csv)
    return vectors, labels, vectors1, labels1

def harmonic_centrality_feature(feature_dir):
    feature_csv = feature_dir + 'pre_harmonic_multi_features.csv'
    vectors, labels = feature_extraction(feature_csv)
    feature_csv = feature_dir + 'post_harmonic_multi_features.csv'
    vectors1, labels1 = feature_extraction(feature_csv)
    return vectors, labels, vectors1, labels1

def no_centrality_feature(feature_dir):
    feature_csv = feature_dir + 'pre_katz_multi_features.csv'
    vectors, labels = feature_extraction(feature_csv)
    feature_csv = feature_dir + 'post_katz_multi_features.csv'
    vectors1, labels1 = feature_extraction(feature_csv)
    return vectors, labels, vectors1, labels1

def random_features(vectors, labels):
    Vec_Lab = []

    for i in range(len(vectors)): #软件个数
        vec = vectors[i]
        lab = labels[i]
        vec.append(lab)
        Vec_Lab.append(vec) #[[api1,api2,...,label], ...]

    random.shuffle(Vec_Lab) #随机排序

    return [m[:-1] for m in Vec_Lab], [m[-1] for m in Vec_Lab]

from sklearn.neighbors import KNeighborsClassifier
def knn_1(vectors, labels, vectors1, labels1):
    X = np.array(vectors)
    Y = np.array(labels)
    X1 = np.array(vectors1)
    Y1 = np.array(labels1)


    F1s = []
    Precisions = []
    Recalls = []
    Accuracys = []

    F1s_p = []
    Precisions_p = []
    Recalls_p = []
    Accuracys_p = []
    # TPRs = []
    # FPRs = []
    # TNRs = []
    # FNRs = []
    kf = KFold(n_splits=5) 
    for train_index, test_index in kf.split(X):
        train_X, train_Y = X[train_index], Y[train_index] #train_X 是对应的训练向量组 train_Y 是标签，各有9/10个
        test_X, test_Y = X[test_index], Y[test_index] #对应的测试组，各有1/10个

        clf = KNeighborsClassifier(n_neighbors=1)
        tic = time.time()
        clf.fit(train_X, train_Y)
        tic1 = time.time()
        print(tic1-tic)
        # tic = time.time()
        y_pred = clf.predict(test_X)
        # tic1 = time.time()
        # print((tic1-tic)/398)
        f1 = f1_score(y_true=test_Y, y_pred=y_pred, average='macro')
        precision = precision_score(y_true=test_Y, y_pred=y_pred, average='macro')
        recall = recall_score(y_true=test_Y, y_pred=y_pred, average='macro')
        accuracy = accuracy_score(y_true=test_Y, y_pred=y_pred, )

        y_pred = clf.predict(X1)
        # tic1 = time.time()
        # print((tic1-tic)/398)
        p_f1 = f1_score(y_true=Y1, y_pred=y_pred, average='macro')
        p_precision = precision_score(y_true=Y1, y_pred=y_pred, average='macro')
        p_recall = recall_score(y_true=Y1, y_pred=y_pred, average='macro')
        p_accuracy = accuracy_score(y_true=Y1, y_pred=y_pred, )

        # print(f1)
        # TP = np.sum(np.multiply(test_Y, y_pred)) #对于0，1时求内积可以反映预测情况，但多分类时就不适用了
        # FP = np.sum(np.logical_and(np.equal(test_Y, 0), np.equal(y_pred, 1)))
        # FN = np.sum(np.logical_and(np.equal(test_Y, 1), np.equal(y_pred, 0)))
        # TN = np.sum(np.logical_and(np.equal(test_Y, 0), np.equal(y_pred, 0)))

        # TPR = TP / (TP + FN)
        # FPR = FP / (FP + TN)
        # TNR = TN / (TN + FP)
        # FNR = FN / (TP + FN)

        F1s.append(f1)
        Precisions.append(precision)
        Recalls.append(recall)
        Accuracys.append(accuracy)

        F1s_p.append(p_f1)
        Precisions_p.append(p_precision)
        Recalls_p.append(p_recall)
        Accuracys_p.append(p_accuracy)
            # TPRs.append(TPR)
            # FPRs.append(FPR)
            # TNRs.append(TNR)
            # FNRs.append(FNR)

        # print(F1s, FPRs)
    print(F1s)
    return [np.mean(F1s), np.mean(Precisions), np.mean(Recalls), np.mean(Accuracys), np.mean(F1s_p), np.mean(Precisions_p), np.mean(Recalls_p), np.mean(Accuracys_p)]

def knn_3(vectors, labels, vectors1, labels1):
    X = np.array(vectors)
    Y = np.array(labels)
    X1 = np.array(vectors1)
    Y1 = np.array(labels1)


    F1s = []
    Precisions = []
    Recalls = []
    Accuracys = []

    F1s_p = []
    Precisions_p = []
    Recalls_p = []
    Accuracys_p = []
    # TPRs = []
    # FPRs = []
    # TNRs = []
    # FNRs = []
    kf = KFold(n_splits=5) 
    for train_index, test_index in kf.split(X):
        train_X, train_Y = X[train_index], Y[train_index] #train_X 是对应的训练向量组 train_Y 是标签，各有9/10个
        test_X, test_Y = X[test_index], Y[test_index] #对应的测试组，各有1/10个

        clf = KNeighborsClassifier(n_neighbors=3)
        tic = time.time()
        clf.fit(train_X, train_Y)
        tic1 = time.time()
        print(tic1-tic)
        # tic = time.time()
        y_pred = clf.predict(test_X)
        # tic1 = time.time()
        # print((tic1-tic)/398)
        f1 = f1_score(y_true=test_Y, y_pred=y_pred, average='macro')
        precision = precision_score(y_true=test_Y, y_pred=y_pred, average='macro')
        recall = recall_score(y_true=test_Y, y_pred=y_pred, average='macro')
        accuracy = accuracy_score(y_true=test_Y, y_pred=y_pred, )

        y_pred = clf.predict(X1)
        # tic1 = time.time()
        # print((tic1-tic)/398)
        p_f1 = f1_score(y_true=Y1, y_pred=y_pred, average='macro')
        p_precision = precision_score(y_true=Y1, y_pred=y_pred, average='macro')
        p_recall = recall_score(y_true=Y1, y_pred=y_pred, average='macro')
        p_accuracy = accuracy_score(y_true=Y1, y_pred=y_pred, )

        # print(f1)
        # TP = np.sum(np.multiply(test_Y, y_pred)) #对于0，1时求内积可以反映预测情况，但多分类时就不适用了
        # FP = np.sum(np.logical_and(np.equal(test_Y, 0), np.equal(y_pred, 1)))
        # FN = np.sum(np.logical_and(np.equal(test_Y, 1), np.equal(y_pred, 0)))
        # TN = np.sum(np.logical_and(np.equal(test_Y, 0), np.equal(y_pred, 0)))

        # TPR = TP / (TP + FN)
        # FPR = FP / (FP + TN)
        # TNR = TN / (TN + FP)
        # FNR = FN / (TP + FN)

        F1s.append(f1)
        Precisions.append(precision)
        Recalls.append(recall)
        Accuracys.append(accuracy)

        F1s_p.append(p_f1)
        Precisions_p.append(p_precision)
        Recalls_p.append(p_recall)
        Accuracys_p.append(p_accuracy)
            # TPRs.append(TPR)
            # FPRs.append(FPR)
            # TNRs.append(TNR)
            # FNRs.append(FNR)

        # print(F1s, FPRs)
    print(F1s)
    return [np.mean(F1s), np.mean(Precisions), np.mean(Recalls), np.mean(Accuracys), np.mean(F1s_p), np.mean(Precisions_p), np.mean(Recalls_p), np.mean(Accuracys_p)]


from sklearn.ensemble import RandomForestClassifier
def randomforest(vectors, labels, vectors1, labels1):
    X = np.array(vectors)
    Y = np.array(labels)
    X1 = np.array(vectors1)
    Y1 = np.array(labels1)

    F1s = []
    Precisions = []
    Recalls = []
    Accuracys = []

    F1s_p = []
    Precisions_p = []
    Recalls_p = []
    Accuracys_p = []
    # TPRs = []
    # FPRs = []
    # TNRs = []
    # FNRs = []


    kf = KFold(n_splits=5) 
    for train_index, test_index in kf.split(X):
        train_X, train_Y = X[train_index], Y[train_index] #train_X 是对应的训练向量组 train_Y 是标签，各有9/10个
        test_X, test_Y = X[test_index], Y[test_index] #对应的测试组，各有1/10个
        clf = RandomForestClassifier(max_depth=256, random_state=0)
        tic = time.time()
        clf.fit(train_X, train_Y)
        tic1 = time.time()
        print(tic1-tic)

        y_pred = clf.predict(test_X)
        f1 = f1_score(y_true=test_Y, y_pred=y_pred, average='macro')
        precision = precision_score(y_true=test_Y, y_pred=y_pred, average='macro')
        recall = recall_score(y_true=test_Y, y_pred=y_pred, average='macro')
        accuracy = accuracy_score(y_true=test_Y, y_pred=y_pred)

        y_pred = clf.predict(X1)
        # tic1 = time.time()
        # print((tic1-tic)/398)
        p_f1 = f1_score(y_true=Y1, y_pred=y_pred, average='macro')
        p_precision = precision_score(y_true=Y1, y_pred=y_pred, average='macro')
        p_recall = recall_score(y_true=Y1, y_pred=y_pred, average='macro')
        p_accuracy = accuracy_score(y_true=Y1, y_pred=y_pred, )

        # print(f1)
        # TP = np.sum(np.multiply(test_Y, y_pred)) #对于0，1时求内积可以反映预测情况，但多分类时就不适用了
        # FP = np.sum(np.logical_and(np.equal(test_Y, 0), np.equal(y_pred, 1)))
        # FN = np.sum(np.logical_and(np.equal(test_Y, 1), np.equal(y_pred, 0)))
        # TN = np.sum(np.logical_and(np.equal(test_Y, 0), np.equal(y_pred, 0)))

        # TPR = TP / (TP + FN)
        # FPR = FP / (FP + TN)
        # TNR = TN / (TN + FP)
        # FNR = FN / (TP + FN)

        F1s.append(f1)
        Precisions.append(precision)
        Recalls.append(recall)
        Accuracys.append(accuracy)

        F1s_p.append(p_f1)
        Precisions_p.append(p_precision)
        Recalls_p.append(p_recall)
        Accuracys_p.append(p_accuracy)
            # TPRs.append(TPR)
            # FPRs.append(FPR)
            # TNRs.append(TNR)
            # FNRs.append(FNR)

    # print(F1s, FPRs)
    print(F1s)
    return [np.mean(F1s), np.mean(Precisions), np.mean(Recalls), np.mean(Accuracys), np.mean(F1s_p), np.mean(Precisions_p), np.mean(Recalls_p), np.mean(Accuracys_p)]


def classification(vectors, labels, vectors1, labels1):
    Vectors, Labels = random_features(vectors, labels)
    Vectors1, Labels1 = random_features(vectors1, labels1)

    csv_data = [[] for i in range(4)]
    csv_data[0] = ['ML_Algorithm', 'F1', 'Precision', 'Recall', 'Accuracy']
    csv_data[1].append('KNN-1')
    csv_data[1].extend(knn_1(Vectors, Labels, Vectors1, Labels1))
    csv_data[2].append('KNN-3')
    csv_data[2].extend(knn_3(Vectors, Labels, Vectors1, Labels1))
    csv_data[3].append('Random Forest')
    csv_data[3].extend(randomforest(Vectors, Labels, Vectors1, Labels1))

    return csv_data


def main():
    args = parseargs()
    feature_dir = args.dir
    out_put = args.output
    type = args.type

    if feature_dir[-1] == '/':
        feature_dir = feature_dir
    else:
        feature_dir += '/'

    if out_put[-1] == '/':
        out_put = out_put
    else:
        out_put += '/'

    if type == 'degree':
        degree_vectors, degree_labels, degree_vectors1, degree_labels1 = degree_centrality_feature(feature_dir)
        degree_csv_data = classification(degree_vectors, degree_labels, degree_vectors1, degree_labels1)
        degree_reults = out_put + 'degree_result.csv'
        with open(degree_reults, 'a+', newline='') as f_degree:
            csvfile = csv.writer(f_degree)
            csvfile.writerows(degree_csv_data)
    elif type == 'harmonic':
        harmonic_vectors, harmonic_labels, harmonic_vectors1, harmonic_labels1 = harmonic_centrality_feature(feature_dir)
        harmonic_csv_data = classification(harmonic_vectors, harmonic_labels, harmonic_vectors1, harmonic_labels1)
        harmonic_reults = out_put + 'harmonic_result.csv'
        with open(harmonic_reults, 'a+', newline='') as f_harmonic:
            csvfile = csv.writer(f_harmonic)
            csvfile.writerows(harmonic_csv_data)
    elif type == 'katz':
        katz_vectors, katz_labels, katz_vectors1, katz_labels1 = katz_centrality_feature(feature_dir)
        katz_csv_data = classification(katz_vectors, katz_labels, katz_vectors1, katz_labels1)
        katz_reults = out_put + 'katz_result.csv'
        with open(katz_reults, 'a+', newline='') as f_katz:
            csvfile = csv.writer(f_katz)
            csvfile.writerows(katz_csv_data)
    elif type == 'closeness':
        closeness_vectors, closeness_labels, closeness_vectors1, closeness_labels1 = closeness_centrality_feature(feature_dir)
        closeness_csv_data = classification(closeness_vectors, closeness_labels, closeness_vectors1, closeness_labels1)
        closeness_reults = out_put + 'closeness_result.csv'
        with open(closeness_reults, 'a+', newline='') as f_closeness:
            csvfile = csv.writer(f_closeness)
            csvfile.writerows(closeness_csv_data)
    elif type == 'no':
        no_vectors, no_labels = no_centrality_feature(feature_dir)
        no_csv_data = classification(no_vectors, no_labels)
        no_reults = out_put + 'no_result.csv'
        with open(no_reults, 'a+', newline='') as f_no:
            csvfile = csv.writer(f_no)
            csvfile.writerows(no_csv_data)
    else:
        print('Error Centrality Type!')


if __name__ == '__main__':
    main()